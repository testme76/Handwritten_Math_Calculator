{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu118\n",
      "CUDA available: True\n",
      "GPU device: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = input('alexli76')\n",
    "key = input('01b753e09563c67314e7c90d9fd4f6a8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil  # Add this import\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import time\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\handwritten-math-symbols\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# Download dataset from Kaggle\n",
    "import opendatasets as od\n",
    "import pandas\n",
    "\n",
    "# Create .kaggle directory if it doesn't exist\n",
    "os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
    "\n",
    "# Create kaggle.json with credentials\n",
    "import json\n",
    "kaggle_token = {\n",
    "    \"username\": username,\n",
    "    \"key\": key\n",
    "}\n",
    "with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'w') as f:\n",
    "    json.dump(kaggle_token, f)\n",
    "\n",
    "# Set permissions\n",
    "os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
    "\n",
    "# Download dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/sagyamthapa/handwritten-math-symbols\"\n",
    "od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting extraction process...\n",
      "Looking for archive at: ./handwritten-math-symbols.zip\n",
      "Archive exists: False\n",
      "\n",
      "Starting file organization...\n",
      "Looking for source directory at: ./handwritten-math-symbols/dataset\n",
      "Source directory exists: True\n",
      "\n",
      "Moving digit folders...\n",
      "Copying ./handwritten-math-symbols/dataset\\0 to ./data/digits\\0\n",
      "Copying ./handwritten-math-symbols/dataset\\1 to ./data/digits\\1\n",
      "Copying ./handwritten-math-symbols/dataset\\2 to ./data/digits\\2\n",
      "Copying ./handwritten-math-symbols/dataset\\3 to ./data/digits\\3\n",
      "Copying ./handwritten-math-symbols/dataset\\4 to ./data/digits\\4\n",
      "Copying ./handwritten-math-symbols/dataset\\5 to ./data/digits\\5\n",
      "Copying ./handwritten-math-symbols/dataset\\6 to ./data/digits\\6\n",
      "Copying ./handwritten-math-symbols/dataset\\7 to ./data/digits\\7\n",
      "Copying ./handwritten-math-symbols/dataset\\8 to ./data/digits\\8\n",
      "Copying ./handwritten-math-symbols/dataset\\9 to ./data/digits\\9\n",
      "\n",
      "Moving operator folders...\n",
      "Copying ./handwritten-math-symbols/dataset\\add to ./data/operators\\add\n",
      "Copying ./handwritten-math-symbols/dataset\\sub to ./data/operators\\sub\n",
      "Copying ./handwritten-math-symbols/dataset\\mul to ./data/operators\\mul\n",
      "Copying ./handwritten-math-symbols/dataset\\div to ./data/operators\\div\n",
      "Copying ./handwritten-math-symbols/dataset\\eq to ./data/operators\\eq\n",
      "Copying ./handwritten-math-symbols/dataset\\dec to ./data/operators\\dec\n",
      "Copying ./handwritten-math-symbols/dataset\\x to ./data/operators\\x\n",
      "Copying ./handwritten-math-symbols/dataset\\y to ./data/operators\\y\n",
      "Copying ./handwritten-math-symbols/dataset\\z to ./data/operators\\z\n",
      "\n",
      "Final verification:\n",
      "\n",
      "Checking directory: ./data/digits\n",
      "Directory exists: True\n",
      "Contents:\n",
      "- 0: 595 images\n",
      "- 1: 562 images\n",
      "- 2: 433 images\n",
      "- 3: 541 images\n",
      "- 4: 526 images\n",
      "- 5: 433 images\n",
      "- 6: 581 images\n",
      "- 7: 533 images\n",
      "- 8: 554 images\n",
      "- 9: 546 images\n",
      "\n",
      "Checking directory: ./data/operators\n",
      "Directory exists: True\n",
      "Contents:\n",
      "- add: 596 images\n",
      "- sub: 655 images\n",
      "- mul: 577 images\n",
      "- div: 618 images\n",
      "- eq: 634 images\n",
      "- dec: 624 images\n",
      "- x: 452 images\n",
      "- y: 399 images\n",
      "- z: 212 images\n",
      "\n",
      "Final image counts:\n",
      "Number of digit images: 5304\n",
      "Number of operator images: 4767\n"
     ]
    }
   ],
   "source": [
    "# Extract dataset from archive with more detailed logging\n",
    "print(\"\\nStarting extraction process...\")\n",
    "dataset_path = \"./handwritten-math-symbols\"\n",
    "archive_path = f\"{dataset_path}.zip\"\n",
    "print(f\"Looking for archive at: {archive_path}\")\n",
    "print(f\"Archive exists: {os.path.exists(archive_path)}\")\n",
    "\n",
    "if os.path.exists(archive_path):\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
    "        # List contents of zip file\n",
    "        print(\"\\nContents of zip file:\")\n",
    "        for file in zip_ref.namelist()[:10]:  # Show first 10 files\n",
    "            print(f\"- {file}\")\n",
    "        print(\"...\")\n",
    "        \n",
    "        zip_ref.extractall(\"./\")\n",
    "    print(\"Dataset extracted successfully\")\n",
    "\n",
    "def verify_directory_structure():\n",
    "    \"\"\"Verify and print the directory structure\"\"\"\n",
    "    print(\"\\nVerifying directory structure:\")\n",
    "    for root, dirs, files in os.walk('./data'):\n",
    "        print(f\"\\nDirectory: {root}\")\n",
    "        print(f\"Subdirectories: {dirs}\")\n",
    "        print(f\"Number of files: {len(files)}\")\n",
    "\n",
    "# First organize the data\n",
    "print(\"\\nStarting file organization...\")\n",
    "source_dir = \"./handwritten-math-symbols/dataset\"\n",
    "print(f\"Looking for source directory at: {source_dir}\")\n",
    "print(f\"Source directory exists: {os.path.exists(source_dir)}\")\n",
    "\n",
    "if not os.path.exists(source_dir):\n",
    "    raise FileNotFoundError(f\"Source directory {source_dir} not found!\")\n",
    "\n",
    "# Create destination directories\n",
    "os.makedirs('./data/digits', exist_ok=True)\n",
    "os.makedirs('./data/operators', exist_ok=True)\n",
    "\n",
    "# Define which folders belong to digits and operators\n",
    "digit_folders = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "operator_folders = ['add', 'sub', 'mul', 'div', 'eq', 'dec', 'x', 'y', 'z']\n",
    "\n",
    "# Move digit folders\n",
    "print(\"\\nMoving digit folders...\")\n",
    "for folder in digit_folders:\n",
    "    src = os.path.join(source_dir, folder)\n",
    "    dst = os.path.join('./data/digits', folder)\n",
    "    if os.path.exists(src):\n",
    "        print(f\"Copying {src} to {dst}\")\n",
    "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "    else:\n",
    "        print(f\"Warning: Source folder not found: {src}\")\n",
    "\n",
    "# Move operator folders\n",
    "print(\"\\nMoving operator folders...\")\n",
    "for folder in operator_folders:\n",
    "    src = os.path.join(source_dir, folder)\n",
    "    dst = os.path.join('./data/operators', folder)\n",
    "    if os.path.exists(src):\n",
    "        print(f\"Copying {src} to {dst}\")\n",
    "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "    else:\n",
    "        print(f\"Warning: Source folder not found: {src}\")\n",
    "\n",
    "# Verify the directory structure\n",
    "verify_directory_structure()\n",
    "\n",
    "# Verify that we have data in the folders\n",
    "print(\"\\nVerifying data in folders:\")\n",
    "digit_path = './data/digits'\n",
    "operator_path = './data/operators'\n",
    "\n",
    "if not os.path.exists(digit_path) or not os.path.exists(operator_path):\n",
    "    raise FileNotFoundError(\"Data directories not created properly!\")\n",
    "\n",
    "digit_classes = sorted(os.listdir(digit_path))\n",
    "operator_classes = sorted(os.listdir(operator_path))\n",
    "\n",
    "print(f\"\\nFound digit classes: {digit_classes}\")\n",
    "print(f\"Found operator classes: {operator_classes}\")\n",
    "\n",
    "if not digit_classes:\n",
    "    raise FileNotFoundError(\"No digit classes found!\")\n",
    "if not operator_classes:\n",
    "    raise FileNotFoundError(\"No operator classes found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1847667668.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[74], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    transform = transforms.Compose([\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Create transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create datasets with error handling\n",
    "try:\n",
    "    digit_dataset = torchvision.datasets.ImageFolder(\n",
    "        root='./data/digits',\n",
    "        transform=transform\n",
    "    )\n",
    "    print(f\"\\nDigit dataset created successfully with {len(digit_dataset)} images\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating digit dataset: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    operator_dataset = torchvision.datasets.ImageFolder(\n",
    "        root='./data/operators',\n",
    "        transform=transform\n",
    "    )\n",
    "    print(f\"Operator dataset created successfully with {len(operator_dataset)} images\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating operator dataset: {e}\")\n",
    "    raise\n",
    "\n",
    "# Create dataloaders\n",
    "digit_trainloader = torch.utils.data.DataLoader(\n",
    "    digit_dataset, \n",
    "    batch_size=32,\n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    "    )\n",
    "\n",
    "operator_trainloader = torch.utils.data.DataLoader(\n",
    "    operator_dataset, \n",
    "    batch_size=32,\n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    "    )\n",
    "\n",
    "print(\"\\nDatasets and dataloaders created successfully!\")\n",
    "print(f\"Number of digit classes: {len(digit_dataset.classes)}\")\n",
    "print(f\"Number of operator classes: {len(operator_dataset.classes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in ./data/digits.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/operators\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create datasets\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m digit_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/digits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m operator_dataset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mImageFolder(\n\u001b[0;32m     21\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/operators\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m     transform\u001b[38;5;241m=\u001b[39mtransform\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Create dataloaders\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    321\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    327\u001b[0m ):\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32mc:\\Users\\alexl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    140\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 149\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[0;32m    152\u001b[0m         class_to_idx\u001b[38;5;241m=\u001b[39mclass_to_idx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32mc:\\Users\\alexl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:43\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     41\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(directory) \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m class_to_idx \u001b[38;5;241m=\u001b[39m {cls_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, cls_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes)}\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in ./data/digits."
     ]
    }
   ],
   "source": [
    "# Define the classes based on the folders\n",
    "digit_classes = sorted(os.listdir('./data/digits'))\n",
    "operator_classes = sorted(os.listdir('./data/operators'))\n",
    "\n",
    "# Define network architectures first\n",
    "class DigitNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitNet, self).__init__()\n",
    "        # Input: 1x32x32\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)  # Output: 6x28x28\n",
    "        self.pool = nn.MaxPool2d(2, 2)    # Output: 6x14x14\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  # Output: 16x10x10\n",
    "        # After second pooling: 16x5x5\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, len(digit_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class OperatorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OperatorNet, self).__init__()\n",
    "        # Input: 1x32x32\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)  # Output: 6x28x28\n",
    "        self.pool = nn.MaxPool2d(2, 2)    # Output: 6x14x14\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  # Output: 16x10x10\n",
    "        # After second pooling: 16x5x5\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, len(operator_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# Initialize networks on CPU first\n",
    "digit_net = DigitNet()\n",
    "operator_net = OperatorNet()\n",
    "\n",
    "# Diagnostic code to check dimensions and classes\n",
    "print(\"\\nDiagnostic Information:\")\n",
    "print(f\"Digit classes: {digit_classes}\")\n",
    "print(f\"Number of digit classes: {len(digit_classes)}\")\n",
    "print(f\"DigitNet output dimension: {digit_net.fc3.out_features}\")\n",
    "\n",
    "print(f\"Operator classes: {operator_classes}\")\n",
    "print(f\"Number of operator classes: {len(operator_classes)}\")\n",
    "print(f\"OperatorNet output dimension: {operator_net.fc3.out_features}\")\n",
    "\n",
    "# Verify network structures before moving to GPU\n",
    "print(\"\\nNetwork Architecture Check:\")\n",
    "print(\"DigitNet:\")\n",
    "print(f\"Input -> Conv1 (1->6) -> Pool -> Conv2 (6->16) -> Pool -> FC1 (400->120) -> FC2 (120->84) -> FC3 (84->{len(digit_classes)})\")\n",
    "print(\"\\nOperatorNet:\")\n",
    "print(f\"Input -> Conv1 (1->6) -> Pool -> Conv2 (6->16) -> Pool -> FC1 (400->120) -> FC2 (120->84) -> FC3 (84->{len(operator_classes)})\")\n",
    "\n",
    "# Try moving to GPU with error handling\n",
    "try:\n",
    "    print(\"\\nMoving networks to GPU...\")\n",
    "    digit_net = digit_net.to(device)\n",
    "    operator_net = operator_net.to(device)\n",
    "    print(\"Successfully moved networks to GPU\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error moving networks to GPU: {e}\")\n",
    "    print(\"Falling back to CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    digit_net = digit_net.to(device)\n",
    "    operator_net = operator_net.to(device)\n",
    "\n",
    "# Create optimizers after moving networks to device\n",
    "digit_optimizer = optim.SGD(digit_net.parameters(), lr=0.001, momentum=0.9)\n",
    "operator_optimizer = optim.SGD(operator_net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Now verify data and label shapes\n",
    "print(\"\\nVerifying data shapes:\")\n",
    "sample_digit_batch = next(iter(digit_trainloader))\n",
    "sample_operator_batch = next(iter(operator_trainloader))\n",
    "\n",
    "print(f\"Digit batch - Images: {sample_digit_batch[0].shape}, Labels: {sample_digit_batch[1].shape}\")\n",
    "print(f\"Operator batch - Images: {sample_operator_batch[0].shape}, Labels: {sample_operator_batch[1].shape}\")\n",
    "\n",
    "# Check label distributions\n",
    "print(\"\\nLabel distributions:\")\n",
    "print(f\"Digit labels unique values: {torch.unique(sample_digit_batch[1])}\")\n",
    "print(f\"Operator labels unique values: {torch.unique(sample_operator_batch[1])}\")\n",
    "\n",
    "# Verify network output dimensions match number of classes\n",
    "with torch.no_grad():\n",
    "    digit_out = digit_net(sample_digit_batch[0].to(device))\n",
    "    operator_out = operator_net(sample_operator_batch[0].to(device))\n",
    "    print(\"\\nNetwork output dimensions:\")\n",
    "    print(f\"DigitNet output: {digit_out.shape}\")\n",
    "    print(f\"OperatorNet output: {operator_out.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m epochs_without_improvement \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Get current date for logging\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m training_date \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Add learning rate scheduler\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "num_epochs = 50\n",
    "eval_interval = 5\n",
    "early_stopping_patience = 15\n",
    "best_digit_accuracy = 0\n",
    "best_operator_accuracy = 0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Get current date for logging\n",
    "training_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Add learning rate scheduler\n",
    "digit_scheduler = ReduceLROnPlateau(digit_optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n",
    "operator_scheduler = ReduceLROnPlateau(operator_optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# Diagnostic code to check dimensions and classes\n",
    "print(\"\\nDiagnostic Information:\")\n",
    "\n",
    "# Check digit dataset\n",
    "digit_classes = sorted(os.listdir('./data/digits'))\n",
    "print(f\"Digit classes: {digit_classes}\")\n",
    "print(f\"Number of digit classes: {len(digit_classes)}\")\n",
    "print(f\"DigitNet output dimension: {digit_net.fc3.out_features}\")\n",
    "\n",
    "# Check operator dataset\n",
    "operator_classes = sorted(os.listdir('./data/operators'))\n",
    "print(f\"Operator classes: {operator_classes}\")\n",
    "print(f\"Number of operator classes: {len(operator_classes)}\")\n",
    "print(f\"OperatorNet output dimension: {operator_net.fc3.out_features}\")\n",
    "\n",
    "# Check a batch of data\n",
    "digit_batch = next(iter(digit_trainloader))\n",
    "operator_batch = next(iter(operator_trainloader))\n",
    "\n",
    "print(\"\\nBatch shapes:\")\n",
    "print(f\"Digit batch - Images: {digit_batch[0].shape}, Labels: {digit_batch[1].shape}\")\n",
    "print(f\"Operator batch - Images: {operator_batch[0].shape}, Labels: {operator_batch[1].shape}\")\n",
    "\n",
    "print(\"\\nLabel ranges:\")\n",
    "print(f\"Digit labels: {digit_batch[1].min().item()} to {digit_batch[1].max().item()}\")\n",
    "print(f\"Operator labels: {operator_batch[1].min().item()} to {operator_batch[1].max().item()}\")\n",
    "\n",
    "\n",
    "# Add criterion definitions before training\n",
    "digit_criterion = nn.CrossEntropyLoss()\n",
    "operator_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Add dataset class mapping\n",
    "digit_dataset.class_to_idx  # Check the mapping of classes to indices\n",
    "operator_dataset.class_to_idx  # Check the mapping of classes to indices\n",
    "\n",
    "# Before training loop, add diagnostic prints\n",
    "print(\"\\nClass mappings:\")\n",
    "print(f\"Digit classes: {digit_dataset.class_to_idx}\")\n",
    "print(f\"Operator classes: {operator_dataset.class_to_idx}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Training digit network\n",
    "    digit_net.train()\n",
    "    digit_running_loss = 0.0\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Add progress bar\n",
    "    pbar = tqdm(digit_trainloader, desc=f\"Training Digit Net\")\n",
    "    for i, data in enumerate(pbar):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        digit_optimizer.zero_grad()\n",
    "        outputs = digit_net(inputs)\n",
    "        loss = digit_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        digit_optimizer.step()\n",
    "        \n",
    "        digit_running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            pbar.set_postfix({'loss': digit_running_loss/100})\n",
    "            digit_running_loss = 0.0\n",
    "    \n",
    "    # Training operator network\n",
    "    operator_net.train()\n",
    "    operator_running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(operator_trainloader, desc=f\"Training Operator Net\")\n",
    "    for i, data in enumerate(pbar):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        operator_optimizer.zero_grad()\n",
    "        outputs = operator_net(inputs)\n",
    "        loss = operator_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        operator_optimizer.step()\n",
    "        \n",
    "        operator_running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            pbar.set_postfix({'loss': operator_running_loss/100})\n",
    "            operator_running_loss = 0.0\n",
    "    \n",
    "    # Evaluation every eval_interval epochs\n",
    "    if epoch % eval_interval == 0:\n",
    "        digit_net.eval()\n",
    "        operator_net.eval()\n",
    "        \n",
    "        # Evaluate digit network\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in digit_trainloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = digit_net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        current_digit_accuracy = 100 * correct / total\n",
    "        print(f\"\\nDigit Network Accuracy: {current_digit_accuracy:.2f}%\")\n",
    "        \n",
    "        # Evaluate operator network\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in operator_trainloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = operator_net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        current_operator_accuracy = 100 * correct / total\n",
    "        print(f\"Operator Network Accuracy: {current_operator_accuracy:.2f}%\")\n",
    "        \n",
    "        # Update schedulers\n",
    "        digit_scheduler.step(current_digit_accuracy)\n",
    "        operator_scheduler.step(current_operator_accuracy)\n",
    "        \n",
    "        # Check for improvement\n",
    "        if current_digit_accuracy > best_digit_accuracy or current_operator_accuracy > best_operator_accuracy:\n",
    "            best_digit_accuracy = max(best_digit_accuracy, current_digit_accuracy)\n",
    "            best_operator_accuracy = max(best_operator_accuracy, current_operator_accuracy)\n",
    "            torch.save(digit_net.state_dict(), 'digit_net_best.pth')\n",
    "            torch.save(operator_net.state_dict(), 'operator_net_best.pth')\n",
    "            epochs_without_improvement = 0\n",
    "            print(\"New best accuracy! Saved models.\")\n",
    "        else:\n",
    "            epochs_without_improvement += eval_interval\n",
    "        \n",
    "        # Early stopping check\n",
    "        if epochs_without_improvement >= early_stopping_patience:\n",
    "            print(\"\\nEarly stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    # Print epoch summary\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Time taken: {epoch_time:.2f} seconds\")\n",
    "    print(f\"Best Digit Accuracy: {best_digit_accuracy:.2f}%\")\n",
    "    print(f\"Best Operator Accuracy: {best_operator_accuracy:.2f}%\")\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
