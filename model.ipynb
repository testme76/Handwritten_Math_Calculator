{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu118\n",
      "CUDA available: True\n",
      "GPU device: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Define device first\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your kaggle user name and key\n",
    "username = str('')\n",
    "key = str('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil  # Add this import\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import time\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying credentials format:\n",
      "Username type: <class 'str'>\n",
      "Key type: <class 'str'>\n",
      "Kaggle credentials saved successfully\n",
      "Skipping, found downloaded files in \".\\handwritten-math-symbols\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# Download dataset from Kaggle\n",
    "import opendatasets as od\n",
    "import pandas\n",
    "import json\n",
    "\n",
    "# Create .kaggle directory if it doesn't exist\n",
    "os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
    "\n",
    "try:\n",
    "    kaggle_token = {\n",
    "        \"username\": username,\n",
    "        \"key\": key\n",
    "    }\n",
    "    \n",
    "    # Verify the data is string\n",
    "    print(\"\\nVerifying credentials format:\")\n",
    "    print(f\"Username type: {type(username)}\")\n",
    "    print(f\"Key type: {type(key)}\")\n",
    "    \n",
    "    with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'w') as f:\n",
    "        json.dump(kaggle_token, f)\n",
    "    \n",
    "    print(\"Kaggle credentials saved successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving Kaggle credentials: {e}\")\n",
    "    raise\n",
    "\n",
    "# Set permissions\n",
    "os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
    "\n",
    "# Download dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/sagyamthapa/handwritten-math-symbols\"\n",
    "od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting extraction process...\n",
      "Looking for archive at: ./handwritten-math-symbols.zip\n",
      "Archive exists: False\n",
      "\n",
      "Starting file organization...\n",
      "Looking for source directory at: ./handwritten-math-symbols/dataset\n",
      "Source directory exists: True\n",
      "\n",
      "Moving digit folders...\n",
      "Copying ./handwritten-math-symbols/dataset\\0 to ./data/combined/digits\\0\n",
      "Copying ./handwritten-math-symbols/dataset\\1 to ./data/combined/digits\\1\n",
      "Copying ./handwritten-math-symbols/dataset\\2 to ./data/combined/digits\\2\n",
      "Copying ./handwritten-math-symbols/dataset\\3 to ./data/combined/digits\\3\n",
      "Copying ./handwritten-math-symbols/dataset\\4 to ./data/combined/digits\\4\n",
      "Copying ./handwritten-math-symbols/dataset\\5 to ./data/combined/digits\\5\n",
      "Copying ./handwritten-math-symbols/dataset\\6 to ./data/combined/digits\\6\n",
      "Copying ./handwritten-math-symbols/dataset\\7 to ./data/combined/digits\\7\n",
      "Copying ./handwritten-math-symbols/dataset\\8 to ./data/combined/digits\\8\n",
      "Copying ./handwritten-math-symbols/dataset\\9 to ./data/combined/digits\\9\n",
      "\n",
      "Moving operator folders...\n",
      "Copying ./handwritten-math-symbols/dataset\\add to ./data/combined/operators\\add\n",
      "Copying ./handwritten-math-symbols/dataset\\sub to ./data/combined/operators\\sub\n",
      "Copying ./handwritten-math-symbols/dataset\\mul to ./data/combined/operators\\mul\n",
      "Copying ./handwritten-math-symbols/dataset\\div to ./data/combined/operators\\div\n",
      "Copying ./handwritten-math-symbols/dataset\\eq to ./data/combined/operators\\eq\n",
      "Copying ./handwritten-math-symbols/dataset\\dec to ./data/combined/operators\\dec\n",
      "Copying ./handwritten-math-symbols/dataset\\x to ./data/combined/operators\\x\n",
      "Copying ./handwritten-math-symbols/dataset\\y to ./data/combined/operators\\y\n",
      "Copying ./handwritten-math-symbols/dataset\\z to ./data/combined/operators\\z\n",
      "\n",
      "Verifying directory structure:\n",
      "\n",
      "Directory: ./data\n",
      "Subdirectories: ['combined', 'digits', 'operators']\n",
      "Number of files: 0\n",
      "\n",
      "Directory: ./data\\combined\n",
      "Subdirectories: ['digits', 'operators']\n",
      "Number of files: 0\n",
      "\n",
      "Directory: ./data\\combined\\digits\n",
      "Subdirectories: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Number of files: 0\n",
      "\n",
      "Directory: ./data\\combined\\digits\\0\n",
      "Subdirectories: []\n",
      "Number of files: 595\n",
      "\n",
      "Directory: ./data\\combined\\digits\\1\n",
      "Subdirectories: []\n",
      "Number of files: 562\n",
      "\n",
      "Directory: ./data\\combined\\digits\\2\n",
      "Subdirectories: []\n",
      "Number of files: 433\n",
      "\n",
      "Directory: ./data\\combined\\digits\\3\n",
      "Subdirectories: []\n",
      "Number of files: 541\n",
      "\n",
      "Directory: ./data\\combined\\digits\\4\n",
      "Subdirectories: []\n",
      "Number of files: 526\n",
      "\n",
      "Directory: ./data\\combined\\digits\\5\n",
      "Subdirectories: []\n",
      "Number of files: 433\n",
      "\n",
      "Directory: ./data\\combined\\digits\\6\n",
      "Subdirectories: []\n",
      "Number of files: 581\n",
      "\n",
      "Directory: ./data\\combined\\digits\\7\n",
      "Subdirectories: []\n",
      "Number of files: 533\n",
      "\n",
      "Directory: ./data\\combined\\digits\\8\n",
      "Subdirectories: []\n",
      "Number of files: 554\n",
      "\n",
      "Directory: ./data\\combined\\digits\\9\n",
      "Subdirectories: []\n",
      "Number of files: 547\n",
      "\n",
      "Directory: ./data\\combined\\operators\n",
      "Subdirectories: ['add', 'dec', 'div', 'eq', 'mul', 'sub', 'x', 'y', 'z']\n",
      "Number of files: 0\n",
      "\n",
      "Directory: ./data\\combined\\operators\\add\n",
      "Subdirectories: []\n",
      "Number of files: 596\n",
      "\n",
      "Directory: ./data\\combined\\operators\\dec\n",
      "Subdirectories: []\n",
      "Number of files: 624\n",
      "\n",
      "Directory: ./data\\combined\\operators\\div\n",
      "Subdirectories: []\n",
      "Number of files: 618\n",
      "\n",
      "Directory: ./data\\combined\\operators\\eq\n",
      "Subdirectories: []\n",
      "Number of files: 634\n",
      "\n",
      "Directory: ./data\\combined\\operators\\mul\n",
      "Subdirectories: []\n",
      "Number of files: 577\n",
      "\n",
      "Directory: ./data\\combined\\operators\\sub\n",
      "Subdirectories: []\n",
      "Number of files: 655\n",
      "\n",
      "Directory: ./data\\combined\\operators\\x\n",
      "Subdirectories: []\n",
      "Number of files: 452\n",
      "\n",
      "Directory: ./data\\combined\\operators\\y\n",
      "Subdirectories: []\n",
      "Number of files: 399\n",
      "\n",
      "Directory: ./data\\combined\\operators\\z\n",
      "Subdirectories: []\n",
      "Number of files: 212\n",
      "\n",
      "Directory: ./data\\digits\n",
      "Subdirectories: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Number of files: 0\n",
      "\n",
      "Directory: ./data\\digits\\0\n",
      "Subdirectories: []\n",
      "Number of files: 595\n",
      "\n",
      "Directory: ./data\\digits\\1\n",
      "Subdirectories: []\n",
      "Number of files: 562\n",
      "\n",
      "Directory: ./data\\digits\\2\n",
      "Subdirectories: []\n",
      "Number of files: 433\n",
      "\n",
      "Directory: ./data\\digits\\3\n",
      "Subdirectories: []\n",
      "Number of files: 541\n",
      "\n",
      "Directory: ./data\\digits\\4\n",
      "Subdirectories: []\n",
      "Number of files: 526\n",
      "\n",
      "Directory: ./data\\digits\\5\n",
      "Subdirectories: []\n",
      "Number of files: 433\n",
      "\n",
      "Directory: ./data\\digits\\6\n",
      "Subdirectories: []\n",
      "Number of files: 581\n",
      "\n",
      "Directory: ./data\\digits\\7\n",
      "Subdirectories: []\n",
      "Number of files: 533\n",
      "\n",
      "Directory: ./data\\digits\\8\n",
      "Subdirectories: []\n",
      "Number of files: 554\n",
      "\n",
      "Directory: ./data\\digits\\9\n",
      "Subdirectories: []\n",
      "Number of files: 547\n",
      "\n",
      "Directory: ./data\\operators\n",
      "Subdirectories: ['add', 'dec', 'div', 'eq', 'mul', 'sub', 'x', 'y', 'z']\n",
      "Number of files: 0\n",
      "\n",
      "Directory: ./data\\operators\\add\n",
      "Subdirectories: []\n",
      "Number of files: 596\n",
      "\n",
      "Directory: ./data\\operators\\dec\n",
      "Subdirectories: []\n",
      "Number of files: 624\n",
      "\n",
      "Directory: ./data\\operators\\div\n",
      "Subdirectories: []\n",
      "Number of files: 618\n",
      "\n",
      "Directory: ./data\\operators\\eq\n",
      "Subdirectories: []\n",
      "Number of files: 634\n",
      "\n",
      "Directory: ./data\\operators\\mul\n",
      "Subdirectories: []\n",
      "Number of files: 577\n",
      "\n",
      "Directory: ./data\\operators\\sub\n",
      "Subdirectories: []\n",
      "Number of files: 655\n",
      "\n",
      "Directory: ./data\\operators\\x\n",
      "Subdirectories: []\n",
      "Number of files: 452\n",
      "\n",
      "Directory: ./data\\operators\\y\n",
      "Subdirectories: []\n",
      "Number of files: 399\n",
      "\n",
      "Directory: ./data\\operators\\z\n",
      "Subdirectories: []\n",
      "Number of files: 212\n",
      "\n",
      "Verifying data in folders:\n",
      "\n",
      "Found digit classes: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Found operator classes: ['add', 'dec', 'div', 'eq', 'mul', 'sub', 'x', 'y', 'z']\n",
      "\n",
      "Class mappings created:\n",
      "Digit classes: {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}\n",
      "Operator classes: {'add': 0, 'dec': 1, 'div': 2, 'eq': 3, 'mul': 4, 'sub': 5, 'x': 6, 'y': 7, 'z': 8}\n",
      "Total classes: 19\n"
     ]
    }
   ],
   "source": [
    "# Extract dataset from archive with more detailed logging\n",
    "print(\"\\nStarting extraction process...\")\n",
    "dataset_path = \"./handwritten-math-symbols\"\n",
    "archive_path = f\"{dataset_path}.zip\"\n",
    "print(f\"Looking for archive at: {archive_path}\")\n",
    "print(f\"Archive exists: {os.path.exists(archive_path)}\")\n",
    "\n",
    "if os.path.exists(archive_path):\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
    "        print(\"\\nContents of zip file:\")\n",
    "        for file in zip_ref.namelist()[:10]:\n",
    "            print(f\"- {file}\")\n",
    "        print(\"...\")\n",
    "        zip_ref.extractall(\"./\")\n",
    "    print(\"Dataset extracted successfully\")\n",
    "\n",
    "def verify_directory_structure():\n",
    "    print(\"\\nVerifying directory structure:\")\n",
    "    for root, dirs, files in os.walk('./data'):\n",
    "        print(f\"\\nDirectory: {root}\")\n",
    "        print(f\"Subdirectories: {dirs}\")\n",
    "        print(f\"Number of files: {len(files)}\")\n",
    "\n",
    "# First organize the data\n",
    "print(\"\\nStarting file organization...\")\n",
    "source_dir = \"./handwritten-math-symbols/dataset\"\n",
    "print(f\"Looking for source directory at: {source_dir}\")\n",
    "print(f\"Source directory exists: {os.path.exists(source_dir)}\")\n",
    "\n",
    "if not os.path.exists(source_dir):\n",
    "    raise FileNotFoundError(f\"Source directory {source_dir} not found!\")\n",
    "\n",
    "# Create destination directories\n",
    "os.makedirs('./data/combined', exist_ok=True)  # New combined directory\n",
    "os.makedirs('./data/combined/digits', exist_ok=True)\n",
    "os.makedirs('./data/combined/operators', exist_ok=True)\n",
    "\n",
    "# Define which folders belong to digits and operators\n",
    "digit_folders = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "operator_folders = ['add', 'sub', 'mul', 'div', 'eq', 'dec', 'x', 'y', 'z']\n",
    "\n",
    "# Move digit folders\n",
    "print(\"\\nMoving digit folders...\")\n",
    "for folder in digit_folders:\n",
    "    src = os.path.join(source_dir, folder)\n",
    "    dst = os.path.join('./data/combined/digits', folder)\n",
    "    if os.path.exists(src):\n",
    "        print(f\"Copying {src} to {dst}\")\n",
    "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "    else:\n",
    "        print(f\"Warning: Source folder not found: {src}\")\n",
    "\n",
    "# Move operator folders\n",
    "print(\"\\nMoving operator folders...\")\n",
    "for folder in operator_folders:\n",
    "    src = os.path.join(source_dir, folder)\n",
    "    dst = os.path.join('./data/combined/operators', folder)\n",
    "    if os.path.exists(src):\n",
    "        print(f\"Copying {src} to {dst}\")\n",
    "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "    else:\n",
    "        print(f\"Warning: Source folder not found: {src}\")\n",
    "\n",
    "# Verify the directory structure\n",
    "verify_directory_structure()\n",
    "\n",
    "# Verify that we have data in the folders\n",
    "print(\"\\nVerifying data in folders:\")\n",
    "digit_path = './data/combined/digits'\n",
    "operator_path = './data/combined/operators'\n",
    "\n",
    "if not os.path.exists(digit_path) or not os.path.exists(operator_path):\n",
    "    raise FileNotFoundError(\"Data directories not created properly!\")\n",
    "\n",
    "digit_classes = sorted(os.listdir(digit_path))\n",
    "operator_classes = sorted(os.listdir(operator_path))\n",
    "\n",
    "print(f\"\\nFound digit classes: {digit_classes}\")\n",
    "print(f\"Found operator classes: {operator_classes}\")\n",
    "\n",
    "# Create class mappings for the combined model\n",
    "class_info = {\n",
    "    'digit_classes': digit_classes,\n",
    "    'operator_classes': operator_classes,\n",
    "    'digit_to_idx': {cls: idx for idx, cls in enumerate(digit_classes)},\n",
    "    'operator_to_idx': {cls: idx for idx, cls in enumerate(operator_classes)},\n",
    "    'num_digit_classes': len(digit_classes),\n",
    "    'num_operator_classes': len(operator_classes)\n",
    "}\n",
    "\n",
    "print(\"\\nClass mappings created:\")\n",
    "print(f\"Digit classes: {class_info['digit_to_idx']}\")\n",
    "print(f\"Operator classes: {class_info['operator_to_idx']}\")\n",
    "print(f\"Total classes: {class_info['num_digit_classes'] + class_info['num_operator_classes']}\")\n",
    "\n",
    "if not digit_classes:\n",
    "    raise FileNotFoundError(\"No digit classes found!\")\n",
    "if not operator_classes:\n",
    "    raise FileNotFoundError(\"No operator classes found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Digit dataset created successfully with 5304 images\n",
      "Operator dataset created successfully with 4767 images\n",
      "\n",
      "Creating dataset splits...\n",
      "Digit - Train: 4243, Val: 530, Test: 531\n",
      "Operator - Train: 3813, Val: 476, Test: 478\n",
      "\n",
      "Datasets and dataloaders created successfully!\n",
      "Number of digit classes: 10\n",
      "Number of operator classes: 9\n",
      "\n",
      "Class mappings:\n",
      "Digit classes: {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}\n",
      "Operator classes: {'add': 0, 'dec': 1, 'div': 2, 'eq': 3, 'mul': 4, 'sub': 5, 'x': 6, 'y': 7, 'z': 8}\n"
     ]
    }
   ],
   "source": [
    "# Create transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create datasets with error handling\n",
    "try:\n",
    "    digit_dataset = torchvision.datasets.ImageFolder(\n",
    "        root='./data/digits',\n",
    "        transform=transform\n",
    "    )\n",
    "    print(f\"\\nDigit dataset created successfully with {len(digit_dataset)} images\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating digit dataset: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    operator_dataset = torchvision.datasets.ImageFolder(\n",
    "        root='./data/operators',\n",
    "        transform=transform\n",
    "    )\n",
    "    print(f\"Operator dataset created successfully with {len(operator_dataset)} images\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating operator dataset: {e}\")\n",
    "    raise\n",
    "\n",
    "# Create dataset splits\n",
    "print(\"\\nCreating dataset splits...\")\n",
    "\n",
    "# For Digit Dataset\n",
    "total_digit_size = len(digit_dataset)\n",
    "train_digit_size = int(0.8 * total_digit_size)\n",
    "val_digit_size = int(0.1 * total_digit_size)\n",
    "test_digit_size = total_digit_size - train_digit_size - val_digit_size\n",
    "\n",
    "digit_train_dataset, digit_val_dataset, digit_test_dataset = random_split(\n",
    "    digit_dataset, \n",
    "    [train_digit_size, val_digit_size, test_digit_size]\n",
    ")\n",
    "\n",
    "# For Operator Dataset\n",
    "total_operator_size = len(operator_dataset)\n",
    "train_operator_size = int(0.8 * total_operator_size)\n",
    "val_operator_size = int(0.1 * total_operator_size)\n",
    "test_operator_size = total_operator_size - train_operator_size - val_operator_size\n",
    "\n",
    "operator_train_dataset, operator_val_dataset, operator_test_dataset = random_split(\n",
    "    operator_dataset, \n",
    "    [train_operator_size, val_operator_size, test_operator_size]\n",
    ")\n",
    "\n",
    "# Create combined dataloaders\n",
    "digit_trainloader = torch.utils.data.DataLoader(\n",
    "    digit_train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "operator_trainloader = torch.utils.data.DataLoader(\n",
    "    operator_train_dataset, \n",
    "    batch_size=32,\n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Create validation dataloaders\n",
    "digit_valloader = torch.utils.data.DataLoader(\n",
    "    digit_val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "operator_valloader = torch.utils.data.DataLoader(\n",
    "    operator_val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Create test dataloaders\n",
    "digit_testloader = torch.utils.data.DataLoader(\n",
    "    digit_test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "operator_testloader = torch.utils.data.DataLoader(\n",
    "    operator_test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Digit - Train: {len(digit_train_dataset)}, Val: {len(digit_val_dataset)}, Test: {len(digit_test_dataset)}\")\n",
    "print(f\"Operator - Train: {len(operator_train_dataset)}, Val: {len(operator_val_dataset)}, Test: {len(operator_test_dataset)}\")\n",
    "\n",
    "# Print dataset information\n",
    "print(\"\\nDatasets and dataloaders created successfully!\")\n",
    "print(f\"Number of digit classes: {len(digit_dataset.classes)}\")\n",
    "print(f\"Number of operator classes: {len(operator_dataset.classes)}\")\n",
    "\n",
    "# Store class information for the combined model\n",
    "num_digit_classes = len(digit_dataset.classes)\n",
    "num_operator_classes = len(operator_dataset.classes)\n",
    "digit_class_to_idx = digit_dataset.class_to_idx\n",
    "operator_class_to_idx = operator_dataset.class_to_idx\n",
    "\n",
    "print(\"\\nClass mappings:\")\n",
    "print(f\"Digit classes: {digit_class_to_idx}\")\n",
    "print(f\"Operator classes: {operator_class_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostic Information:\n",
      "Digit classes: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Number of digit classes: 10\n",
      "Operator classes: ['add', 'dec', 'div', 'eq', 'mul', 'sub', 'x', 'y', 'z']\n",
      "Number of operator classes: 9\n",
      "\n",
      "Network Architecture Check:\n",
      "CombinedNet outputs:\n",
      "Type classification: 2 classes (digit/operator)\n",
      "Digit classification: 10 classes\n",
      "Operator classification: 9 classes\n",
      "\n",
      "Moving network to GPU...\n",
      "Successfully moved network to GPU\n",
      "\n",
      "Verifying data shapes:\n",
      "Digit batch - Images: torch.Size([32, 1, 32, 32]), Labels: torch.Size([32])\n",
      "Operator batch - Images: torch.Size([32, 1, 32, 32]), Labels: torch.Size([32])\n",
      "\n",
      "Network output dimensions:\n",
      "Type output: torch.Size([32, 2])\n",
      "Digit output: torch.Size([32, 10])\n",
      "Operator output: torch.Size([32, 9])\n"
     ]
    }
   ],
   "source": [
    "# Define the classes based on the folders\n",
    "digit_classes = sorted(os.listdir('./data/digits'))\n",
    "operator_classes = sorted(os.listdir('./data/operators'))\n",
    "\n",
    "class CombinedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedNet, self).__init__()\n",
    "        # First conv block\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)  # 32x32 -> 32x32\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)  # 32x32 -> 32x32\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # 32x32 -> 16x16\n",
    "        \n",
    "        # Second conv block\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)  # 16x16 -> 16x16\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)  # 16x16 -> 16x16\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 16x16 -> 8x8\n",
    "        \n",
    "        # Third conv block\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)  # 8x8 -> 8x8\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # 8x8 -> 4x4\n",
    "        \n",
    "        # Shared features end here\n",
    "        \n",
    "        # Type classification (digit vs operator)\n",
    "        self.type_fc = nn.Linear(128 * 4 * 4, 2)\n",
    "        \n",
    "        # Digit classification (0-9)\n",
    "        self.digit_fc = nn.Linear(128 * 4 * 4, len(digit_classes))\n",
    "        \n",
    "        # Operator classification\n",
    "        self.operator_fc = nn.Linear(128 * 4 * 4, len(operator_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First block\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Second block\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Third block\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Flatten\n",
    "        features = x.view(-1, 128 * 4 * 4)\n",
    "        \n",
    "        # Get all predictions\n",
    "        type_out = self.type_fc(features)      # Is it digit or operator?\n",
    "        digit_out = self.digit_fc(features)    # If digit, which one?\n",
    "        operator_out = self.operator_fc(features)  # If operator, which one?\n",
    "        \n",
    "        return type_out, digit_out, operator_out\n",
    "\n",
    "\n",
    "# Initialize the combined network\n",
    "combined_net = CombinedNet().to(device)\n",
    "\n",
    "# Single optimizer for the combined network\n",
    "optimizer = optim.Adam(combined_net.parameters(), lr=0.0001)\n",
    "\n",
    "def predict_with_threshold(image, model, device, type_threshold=0.8):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Ensure image is on the correct device\n",
    "        if not isinstance(image, torch.Tensor):\n",
    "            image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "        image = image.to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        type_out, digit_out, operator_out = model(image)\n",
    "        \n",
    "        # Get all probabilities\n",
    "        type_prob = F.softmax(type_out, dim=1)\n",
    "        digit_prob = F.softmax(digit_out, dim=1)\n",
    "        operator_prob = F.softmax(operator_out, dim=1)\n",
    "        \n",
    "        type_conf, type_pred = torch.max(type_prob, 1)\n",
    "        digit_conf, digit_pred = torch.max(digit_prob, 1)\n",
    "        operator_conf, operator_pred = torch.max(operator_prob, 1)\n",
    "        \n",
    "        # Only trust type prediction if confident enough\n",
    "        if type_conf >= type_threshold:\n",
    "            if type_pred == 0:  # Digit\n",
    "                return 'digit', digit_pred.item(), digit_conf.item()\n",
    "            else:  # Operator\n",
    "                return 'operator', operator_pred.item(), operator_conf.item()\n",
    "        else:\n",
    "            # If not confident about type, use highest confidence between digit and operator\n",
    "            if digit_conf > operator_conf:\n",
    "                return 'digit', digit_pred.item(), digit_conf.item()\n",
    "            else:\n",
    "                return 'operator', operator_pred.item(), operator_conf.item()\n",
    "\n",
    "\n",
    "# Diagnostic code to check dimensions and classes\n",
    "print(\"\\nDiagnostic Information:\")\n",
    "print(f\"Digit classes: {digit_classes}\")\n",
    "print(f\"Number of digit classes: {len(digit_classes)}\")\n",
    "print(f\"Operator classes: {operator_classes}\")\n",
    "print(f\"Number of operator classes: {len(operator_classes)}\")\n",
    "\n",
    "# Verify network structure\n",
    "print(\"\\nNetwork Architecture Check:\")\n",
    "print(\"CombinedNet outputs:\")\n",
    "print(f\"Type classification: 2 classes (digit/operator)\")\n",
    "print(f\"Digit classification: {len(digit_classes)} classes\")\n",
    "print(f\"Operator classification: {len(operator_classes)} classes\")\n",
    "\n",
    "# Try moving to GPU with error handling\n",
    "try:\n",
    "    print(\"\\nMoving network to GPU...\")\n",
    "    combined_net = combined_net.to(device)\n",
    "    print(\"Successfully moved network to GPU\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error moving network to GPU: {e}\")\n",
    "    print(\"Falling back to CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    combined_net = combined_net.to(device)\n",
    "\n",
    "# Now verify data and label shapes\n",
    "print(\"\\nVerifying data shapes:\")\n",
    "sample_digit_batch = next(iter(digit_trainloader))\n",
    "sample_operator_batch = next(iter(operator_trainloader))\n",
    "\n",
    "print(f\"Digit batch - Images: {sample_digit_batch[0].shape}, Labels: {sample_digit_batch[1].shape}\")\n",
    "print(f\"Operator batch - Images: {sample_operator_batch[0].shape}, Labels: {sample_operator_batch[1].shape}\")\n",
    "\n",
    "# Verify network output dimensions\n",
    "with torch.no_grad():\n",
    "    type_out, digit_out, operator_out = combined_net(sample_digit_batch[0].to(device))\n",
    "    print(\"\\nNetwork output dimensions:\")\n",
    "    print(f\"Type output: {type_out.shape}\")\n",
    "    print(f\"Digit output: {digit_out.shape}\")\n",
    "    print(f\"Operator output: {operator_out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 50.62it/s, loss=3.16, type_loss=0.384, digit_loss=1.17, operator_loss=0.537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracies:\n",
      "Type Classification: 90.17%\n",
      "Digit Recognition: 65.27%\n",
      "Operator Recognition: 84.73%\n",
      "New best accuracy! Saved model.\n",
      "\n",
      "Epoch 1/50\n",
      "Time taken: 17.74 seconds\n",
      "Best Accuracy: 90.17%\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:01<00:00, 60.14it/s, loss=1.53, type_loss=0.36, digit_loss=0.912, operator_loss=0.542] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/50\n",
      "Time taken: 9.04 seconds\n",
      "Best Accuracy: 90.17%\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.02it/s, loss=0.963, type_loss=0.223, digit_loss=0.561, operator_loss=0.37]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/50\n",
      "Time taken: 9.16 seconds\n",
      "Best Accuracy: 90.17%\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.78it/s, loss=0.674, type_loss=0.13, digit_loss=0.288, operator_loss=0.194]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/50\n",
      "Time taken: 9.19 seconds\n",
      "Best Accuracy: 90.17%\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:01<00:00, 60.48it/s, loss=0.495, type_loss=0.241, digit_loss=0.19, operator_loss=0.0826]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/50\n",
      "Time taken: 9.06 seconds\n",
      "Best Accuracy: 90.17%\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.97it/s, loss=0.369, type_loss=0.0777, digit_loss=0.127, operator_loss=0.0111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracies:\n",
      "Type Classification: 95.92%\n",
      "Digit Recognition: 92.26%\n",
      "Operator Recognition: 96.86%\n",
      "New best accuracy! Saved model.\n",
      "\n",
      "Epoch 6/50\n",
      "Time taken: 17.15 seconds\n",
      "Best Accuracy: 95.92%\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.80it/s, loss=0.287, type_loss=0.0723, digit_loss=0.161, operator_loss=0.0288] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/50\n",
      "Time taken: 9.19 seconds\n",
      "Best Accuracy: 95.92%\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.53it/s, loss=0.226, type_loss=0.1, digit_loss=0.1, operator_loss=0.0352]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/50\n",
      "Time taken: 9.13 seconds\n",
      "Best Accuracy: 95.92%\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 56.23it/s, loss=0.181, type_loss=0.0996, digit_loss=0.0792, operator_loss=0.0274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/50\n",
      "Time taken: 9.13 seconds\n",
      "Best Accuracy: 95.92%\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 57.06it/s, loss=0.137, type_loss=0.0685, digit_loss=0.124, operator_loss=0.0316]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/50\n",
      "Time taken: 9.16 seconds\n",
      "Best Accuracy: 95.92%\n",
      "\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.32it/s, loss=0.115, type_loss=0.103, digit_loss=0.0654, operator_loss=0.0177]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracies:\n",
      "Type Classification: 98.01%\n",
      "Digit Recognition: 97.07%\n",
      "Operator Recognition: 98.33%\n",
      "New best accuracy! Saved model.\n",
      "\n",
      "Epoch 11/50\n",
      "Time taken: 17.18 seconds\n",
      "Best Accuracy: 98.01%\n",
      "\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.91it/s, loss=0.0911, type_loss=0.0251, digit_loss=0.0139, operator_loss=0.0123] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/50\n",
      "Time taken: 9.20 seconds\n",
      "Best Accuracy: 98.01%\n",
      "\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 56.21it/s, loss=0.0767, type_loss=0.0908, digit_loss=0.0324, operator_loss=0.0394] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/50\n",
      "Time taken: 9.21 seconds\n",
      "Best Accuracy: 98.01%\n",
      "\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.44it/s, loss=0.063, type_loss=0.0547, digit_loss=0.0631, operator_loss=0.0119]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/50\n",
      "Time taken: 9.21 seconds\n",
      "Best Accuracy: 98.01%\n",
      "\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.11it/s, loss=0.0521, type_loss=0.0564, digit_loss=0.028, operator_loss=0.00955]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/50\n",
      "Time taken: 9.21 seconds\n",
      "Best Accuracy: 98.01%\n",
      "\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 56.33it/s, loss=0.0449, type_loss=0.0586, digit_loss=0.0331, operator_loss=0.0126]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracies:\n",
      "Type Classification: 98.54%\n",
      "Digit Recognition: 97.70%\n",
      "Operator Recognition: 98.54%\n",
      "New best accuracy! Saved model.\n",
      "\n",
      "Epoch 16/50\n",
      "Time taken: 17.09 seconds\n",
      "Best Accuracy: 98.54%\n",
      "\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.82it/s, loss=0.0385, type_loss=0.0733, digit_loss=0.0187, operator_loss=0.0516]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/50\n",
      "Time taken: 9.17 seconds\n",
      "Best Accuracy: 98.54%\n",
      "\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 58.12it/s, loss=0.0336, type_loss=0.0325, digit_loss=0.0222, operator_loss=0.0202]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/50\n",
      "Time taken: 9.10 seconds\n",
      "Best Accuracy: 98.54%\n",
      "\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.67it/s, loss=0.0283, type_loss=0.0335, digit_loss=0.0137, operator_loss=0.00473]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/50\n",
      "Time taken: 9.21 seconds\n",
      "Best Accuracy: 98.54%\n",
      "\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.98it/s, loss=0.0245, type_loss=0.0167, digit_loss=0.0201, operator_loss=0.00184] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/50\n",
      "Time taken: 9.42 seconds\n",
      "Best Accuracy: 98.54%\n",
      "\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.88it/s, loss=0.0212, type_loss=0.0378, digit_loss=0.0142, operator_loss=0.0249]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracies:\n",
      "Type Classification: 98.85%\n",
      "Digit Recognition: 98.54%\n",
      "Operator Recognition: 98.74%\n",
      "New best accuracy! Saved model.\n",
      "\n",
      "Epoch 21/50\n",
      "Time taken: 18.17 seconds\n",
      "Best Accuracy: 98.85%\n",
      "\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 56.33it/s, loss=0.0195, type_loss=0.0138, digit_loss=0.00958, operator_loss=0.0012]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/50\n",
      "Time taken: 9.31 seconds\n",
      "Best Accuracy: 98.85%\n",
      "\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.51it/s, loss=0.0166, type_loss=0.0446, digit_loss=0.00633, operator_loss=0.0148]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/50\n",
      "Time taken: 9.39 seconds\n",
      "Best Accuracy: 98.85%\n",
      "\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.50it/s, loss=0.0161, type_loss=0.0516, digit_loss=0.018, operator_loss=0.00654]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/50\n",
      "Time taken: 9.31 seconds\n",
      "Best Accuracy: 98.85%\n",
      "\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.85it/s, loss=0.0161, type_loss=0.0151, digit_loss=0.0052, operator_loss=0.00711]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/50\n",
      "Time taken: 9.24 seconds\n",
      "Best Accuracy: 98.85%\n",
      "\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.60it/s, loss=0.0124, type_loss=0.023, digit_loss=0.00751, operator_loss=0.0131]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracies:\n",
      "Type Classification: 98.74%\n",
      "Digit Recognition: 98.54%\n",
      "Operator Recognition: 98.95%\n",
      "\n",
      "Epoch 26/50\n",
      "Time taken: 17.16 seconds\n",
      "Best Accuracy: 98.85%\n",
      "\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.62it/s, loss=0.0117, type_loss=0.00433, digit_loss=0.00614, operator_loss=0.00214] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/50\n",
      "Time taken: 9.24 seconds\n",
      "Best Accuracy: 98.85%\n",
      "\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 59.14it/s, loss=0.0102, type_loss=0.0122, digit_loss=0.00633, operator_loss=0.00469]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/50\n",
      "Time taken: 9.28 seconds\n",
      "Best Accuracy: 98.85%\n",
      "\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 51.94it/s, loss=0.00945, type_loss=0.0353, digit_loss=0.00976, operator_loss=0.0116]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/50\n",
      "Time taken: 9.42 seconds\n",
      "Best Accuracy: 98.85%\n",
      "\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 52.97it/s, loss=0.0117, type_loss=0.023, digit_loss=0.0157, operator_loss=0.000968]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/50\n",
      "Time taken: 9.79 seconds\n",
      "Best Accuracy: 98.85%\n",
      "\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.98it/s, loss=0.0107, type_loss=0.023, digit_loss=0.0111, operator_loss=0.000847]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracies:\n",
      "Type Classification: 98.95%\n",
      "Digit Recognition: 98.12%\n",
      "Operator Recognition: 98.95%\n",
      "New best accuracy! Saved model.\n",
      "\n",
      "Epoch 31/50\n",
      "Time taken: 17.36 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.87it/s, loss=0.00821, type_loss=0.00969, digit_loss=0.0023, operator_loss=0.00267]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/50\n",
      "Time taken: 9.31 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 53.43it/s, loss=0.00739, type_loss=0.00812, digit_loss=0.00428, operator_loss=0.0012]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33/50\n",
      "Time taken: 9.43 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 53.65it/s, loss=0.00698, type_loss=0.00659, digit_loss=0.00435, operator_loss=0.000843] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/50\n",
      "Time taken: 9.36 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.41it/s, loss=0.00543, type_loss=0.00978, digit_loss=0.00387, operator_loss=0.00105]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/50\n",
      "Time taken: 9.40 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.49it/s, loss=0.0053, type_loss=0.0117, digit_loss=0.00541, operator_loss=0.00512]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracies:\n",
      "Type Classification: 98.95%\n",
      "Digit Recognition: 97.49%\n",
      "Operator Recognition: 98.95%\n",
      "\n",
      "Epoch 36/50\n",
      "Time taken: 17.27 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.88it/s, loss=0.00783, type_loss=0.0416, digit_loss=0.00321, operator_loss=0.00413]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/50\n",
      "Time taken: 9.12 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.55it/s, loss=0.0136, type_loss=0.00708, digit_loss=0.00269, operator_loss=0.00878]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/50\n",
      "Time taken: 9.16 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.01it/s, loss=0.00588, type_loss=0.0327, digit_loss=0.00255, operator_loss=0.000633]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/50\n",
      "Time taken: 9.17 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 56.72it/s, loss=0.00717, type_loss=0.0122, digit_loss=0.00155, operator_loss=0.00707]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/50\n",
      "Time taken: 9.02 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 56.59it/s, loss=0.00546, type_loss=0.00653, digit_loss=0.00402, operator_loss=0.000314] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracies:\n",
      "Type Classification: 98.64%\n",
      "Digit Recognition: 97.28%\n",
      "Operator Recognition: 98.54%\n",
      "\n",
      "Epoch 41/50\n",
      "Time taken: 16.94 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.76it/s, loss=0.0043, type_loss=0.0173, digit_loss=0.00144, operator_loss=0.00147]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42/50\n",
      "Time taken: 9.08 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.50it/s, loss=0.00528, type_loss=0.00899, digit_loss=0.00311, operator_loss=0.0015]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43/50\n",
      "Time taken: 9.18 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.07it/s, loss=0.00492, type_loss=0.0117, digit_loss=0.00194, operator_loss=0.00128]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44/50\n",
      "Time taken: 9.17 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 55.27it/s, loss=0.00415, type_loss=0.00878, digit_loss=0.00147, operator_loss=0.000655]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45/50\n",
      "Time taken: 9.13 seconds\n",
      "Best Accuracy: 98.95%\n",
      "\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [00:02<00:00, 54.32it/s, loss=0.00374, type_loss=0.00408, digit_loss=0.00195, operator_loss=0.00123]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracies:\n",
      "Type Classification: 98.85%\n",
      "Digit Recognition: 98.12%\n",
      "Operator Recognition: 98.95%\n",
      "\n",
      "Early stopping triggered!\n",
      "Finished Training\n",
      "\n",
      "Saving final model weights...\n",
      "Final weights saved successfully: ./weights/combined_net_final.pth\n",
      "\n",
      "Best weights were saved during training: ./weights/combined_net_best.pth\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "num_epochs = 50\n",
    "eval_interval = 5\n",
    "early_stopping_patience = 15\n",
    "best_accuracy = 0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Get current date for logging\n",
    "training_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Add learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# Add criterion definitions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create weights directory if it doesn't exist\n",
    "os.makedirs('./weights', exist_ok=True)\n",
    "best_model_path = './weights/combined_net_best.pth'\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    combined_net.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Calculate number of batches\n",
    "    n_batches = min(len(digit_trainloader), len(operator_trainloader))\n",
    "    \n",
    "    # Add progress bar with known length\n",
    "    pbar = tqdm(zip(digit_trainloader, operator_trainloader), \n",
    "                total=n_batches,  # Set total number of batches\n",
    "                desc=f\"Training\")\n",
    "    \n",
    "    for batch_idx, (digit_data, operator_data) in enumerate(pbar):\n",
    "        # Prepare digit data\n",
    "        digit_inputs, digit_labels = digit_data\n",
    "        digit_inputs, digit_labels = digit_inputs.to(device), digit_labels.to(device)\n",
    "        digit_type = torch.zeros(digit_inputs.size(0), dtype=torch.long).to(device)\n",
    "        \n",
    "        # Prepare operator data\n",
    "        operator_inputs, operator_labels = operator_data\n",
    "        operator_inputs, operator_labels = operator_inputs.to(device), operator_labels.to(device)\n",
    "        operator_type = torch.ones(operator_inputs.size(0), dtype=torch.long).to(device)\n",
    "        \n",
    "        # Combined batch\n",
    "        inputs = torch.cat([digit_inputs, operator_inputs])\n",
    "        type_labels = torch.cat([digit_type, operator_type])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        type_out, digit_out, operator_out = combined_net(inputs)\n",
    "        \n",
    "        # Calculate losses\n",
    "        type_loss = criterion(type_out, type_labels)\n",
    "        digit_loss = criterion(digit_out[:len(digit_type)], digit_labels)\n",
    "        operator_loss = criterion(operator_out[len(digit_type):], operator_labels)\n",
    "        \n",
    "        # Combined loss\n",
    "        loss = type_loss + digit_loss + operator_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': running_loss/(batch_idx + 1),\n",
    "            'type_loss': type_loss.item(),\n",
    "            'digit_loss': digit_loss.item(),\n",
    "            'operator_loss': operator_loss.item()\n",
    "        })\n",
    "    \n",
    "    # Evaluation every eval_interval epochs\n",
    "    if epoch % eval_interval == 0:\n",
    "        combined_net.eval()\n",
    "        \n",
    "        correct_type = 0\n",
    "        correct_digit = 0\n",
    "        correct_operator = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Evaluate on validation set\n",
    "            for digit_data, operator_data in zip(digit_valloader, operator_valloader):\n",
    "                # Process digit data\n",
    "                digit_inputs, digit_labels = digit_data\n",
    "                digit_inputs = digit_inputs.to(device)\n",
    "                digit_type = torch.zeros(digit_inputs.size(0), dtype=torch.long).to(device)\n",
    "                \n",
    "                # Process operator data\n",
    "                operator_inputs, operator_labels = operator_data\n",
    "                operator_inputs = operator_inputs.to(device)\n",
    "                operator_type = torch.ones(operator_inputs.size(0), dtype=torch.long).to(device)\n",
    "                \n",
    "                # Combined validation\n",
    "                inputs = torch.cat([digit_inputs, operator_inputs])\n",
    "                type_labels = torch.cat([digit_type, operator_type])\n",
    "                \n",
    "                type_out, digit_out, operator_out = combined_net(inputs)\n",
    "                \n",
    "                # Calculate accuracies\n",
    "                _, predicted_type = torch.max(type_out.data, 1)\n",
    "                correct_type += (predicted_type == type_labels).sum().item()\n",
    "                \n",
    "                _, predicted_digit = torch.max(digit_out[:len(digit_type)].data, 1)\n",
    "                correct_digit += (predicted_digit == digit_labels.to(device)).sum().item()\n",
    "                \n",
    "                _, predicted_operator = torch.max(operator_out[len(digit_type):].data, 1)\n",
    "                correct_operator += (predicted_operator == operator_labels.to(device)).sum().item()\n",
    "                \n",
    "                total += type_labels.size(0)\n",
    "        \n",
    "        type_accuracy = 100 * correct_type / total\n",
    "        digit_accuracy = 100 * correct_digit / (total/2)\n",
    "        operator_accuracy = 100 * correct_operator / (total/2)\n",
    "        \n",
    "        print(f\"\\nValidation Accuracies:\")\n",
    "        print(f\"Type Classification: {type_accuracy:.2f}%\")\n",
    "        print(f\"Digit Recognition: {digit_accuracy:.2f}%\")\n",
    "        print(f\"Operator Recognition: {operator_accuracy:.2f}%\")\n",
    "        \n",
    "        # Update scheduler based on type accuracy\n",
    "        scheduler.step(type_accuracy)\n",
    "        \n",
    "        # Save best model based on type accuracy\n",
    "        if type_accuracy > best_accuracy:\n",
    "            best_accuracy = type_accuracy\n",
    "            torch.save(combined_net.state_dict(), best_model_path)\n",
    "            epochs_without_improvement = 0\n",
    "            print(\"New best accuracy! Saved model.\")\n",
    "        else:\n",
    "            epochs_without_improvement += eval_interval\n",
    "        \n",
    "        # Early stopping check\n",
    "        if epochs_without_improvement >= early_stopping_patience:\n",
    "            print(\"\\nEarly stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    # Print epoch summary\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Time taken: {epoch_time:.2f} seconds\")\n",
    "    print(f\"Best Accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save final weights\n",
    "print(\"\\nSaving final model weights...\")\n",
    "try:\n",
    "    final_model_path = './weights/combined_net_final.pth'\n",
    "    torch.save(combined_net.state_dict(), final_model_path)\n",
    "    print(f\"Final weights saved successfully: {final_model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving final weights: {e}\")\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"\\nBest weights were saved during training: {best_model_path}\")\n",
    "else:\n",
    "    print(\"\\nWarning: Best weight file not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing final test evaluation...\n",
      "\n",
      "Final Test Results:\n",
      "Type Classification Accuracy: 99.16%\n",
      "Digit Recognition Accuracy: 98.75%\n",
      "Operator Recognition Accuracy: 98.75%\n",
      "\n",
      "Testing complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPerforming final test evaluation...\")\n",
    "combined_net.eval()\n",
    "\n",
    "# Create test dataloaders\n",
    "digit_testloader = DataLoader(digit_test_dataset, batch_size=32, shuffle=False)\n",
    "operator_testloader = DataLoader(operator_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct_type = 0\n",
    "    correct_digit = 0\n",
    "    correct_operator = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Test on both digit and operator data\n",
    "    for digit_data, operator_data in zip(digit_testloader, operator_testloader):\n",
    "        # Process digit data\n",
    "        digit_inputs, digit_labels = digit_data\n",
    "        digit_inputs = digit_inputs.to(device)\n",
    "        digit_type = torch.zeros(digit_inputs.size(0), dtype=torch.long).to(device)  # 0 for digits\n",
    "        \n",
    "        # Process operator data\n",
    "        operator_inputs, operator_labels = operator_data\n",
    "        operator_inputs = operator_inputs.to(device)\n",
    "        operator_type = torch.ones(operator_inputs.size(0), dtype=torch.long).to(device)  # 1 for operators\n",
    "        \n",
    "        # Combined test batch\n",
    "        inputs = torch.cat([digit_inputs, operator_inputs])\n",
    "        type_labels = torch.cat([digit_type, operator_type])\n",
    "        \n",
    "        # Get predictions\n",
    "        type_out, digit_out, operator_out = combined_net(inputs)\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        _, predicted_type = torch.max(type_out.data, 1)\n",
    "        correct_type += (predicted_type == type_labels).sum().item()\n",
    "        \n",
    "        _, predicted_digit = torch.max(digit_out[:len(digit_type)].data, 1)\n",
    "        correct_digit += (predicted_digit == digit_labels.to(device)).sum().item()\n",
    "        \n",
    "        _, predicted_operator = torch.max(operator_out[len(digit_type):].data, 1)\n",
    "        correct_operator += (predicted_operator == operator_labels.to(device)).sum().item()\n",
    "        \n",
    "        total += type_labels.size(0)\n",
    "\n",
    "    # Calculate final accuracies\n",
    "    test_type_accuracy = 100 * correct_type / total\n",
    "    test_digit_accuracy = 100 * correct_digit / (total/2)\n",
    "    test_operator_accuracy = 100 * correct_operator / (total/2)\n",
    "    \n",
    "    print(\"\\nFinal Test Results:\")\n",
    "    print(f\"Type Classification Accuracy: {test_type_accuracy:.2f}%\")\n",
    "    print(f\"Digit Recognition Accuracy: {test_digit_accuracy:.2f}%\")\n",
    "    print(f\"Operator Recognition Accuracy: {test_operator_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nTesting complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing threshold-based evaluation...\n",
      "\n",
      "Testing with threshold 0.7:\n",
      "Overall Accuracy with threshold 0.7: 98.22%\n",
      "\n",
      "Testing with threshold 0.8:\n",
      "Overall Accuracy with threshold 0.8: 98.32%\n",
      "\n",
      "Testing with threshold 0.9:\n",
      "Overall Accuracy with threshold 0.9: 98.32%\n",
      "\n",
      "Threshold-based testing complete!\n"
     ]
    }
   ],
   "source": [
    "# Second: Add threshold-based evaluation\n",
    "def predict_with_threshold(image, type_threshold=0.8):\n",
    "    \"\"\"Predict with confidence threshold\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Get predictions\n",
    "        type_out, digit_out, operator_out = combined_net(image)\n",
    "        \n",
    "        # Get all probabilities\n",
    "        type_prob = F.softmax(type_out, dim=1)\n",
    "        digit_prob = F.softmax(digit_out, dim=1)\n",
    "        operator_prob = F.softmax(operator_out, dim=1)\n",
    "        \n",
    "        type_conf, type_pred = torch.max(type_prob, 1)\n",
    "        digit_conf, digit_pred = torch.max(digit_prob, 1)\n",
    "        operator_conf, operator_pred = torch.max(operator_prob, 1)\n",
    "        \n",
    "        # Only trust type prediction if confident enough\n",
    "        if type_conf >= type_threshold:\n",
    "            if type_pred == 0:  # Digit\n",
    "                return 'digit', digit_pred.item(), digit_conf.item()\n",
    "            else:  # Operator\n",
    "                return 'operator', operator_pred.item(), operator_conf.item()\n",
    "        else:\n",
    "            # If not confident about type, use highest confidence\n",
    "            if digit_conf > operator_conf:\n",
    "                return 'digit', digit_pred.item(), digit_conf.item()\n",
    "            else:\n",
    "                return 'operator', operator_pred.item(), operator_conf.item()\n",
    "\n",
    "print(\"\\nPerforming threshold-based evaluation...\")\n",
    "# Test with different thresholds\n",
    "thresholds = [0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    print(f\"\\nTesting with threshold {threshold}:\")\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Test digits\n",
    "        for images, labels in digit_testloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            for i in range(len(images)):\n",
    "                pred_type, pred_class, conf = predict_with_threshold(\n",
    "                    images[i].unsqueeze(0),  # Add batch dimension\n",
    "                    threshold\n",
    "                )\n",
    "                if pred_type == 'digit' and pred_class == labels[i].item():\n",
    "                    correct_predictions += 1\n",
    "                total_predictions += 1\n",
    "        \n",
    "        # Test operators\n",
    "        for images, labels in operator_testloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            for i in range(len(images)):\n",
    "                pred_type, pred_class, conf = predict_with_threshold(\n",
    "                    images[i].unsqueeze(0),  # Add batch dimension\n",
    "                    threshold\n",
    "                )\n",
    "                if pred_type == 'operator' and pred_class == labels[i].item():\n",
    "                    correct_predictions += 1\n",
    "                total_predictions += 1\n",
    "    \n",
    "    accuracy = 100 * correct_predictions / total_predictions\n",
    "    print(f\"Overall Accuracy with threshold {threshold}: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nThreshold-based testing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
